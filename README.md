# TinyLlama Chatbot ğŸš€

Este repositÃ³rio contÃ©m um exemplo de chatbot utilizando o modelo **[TinyLlama/TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)** atravÃ©s da biblioteca [Transformers](https://huggingface.co/docs/transformers/index) da Hugging Face.  

O cÃ³digo foi desenvolvido em **Python** e permite conversas interativas em linha de comando, aproveitando GPU (se disponÃ­vel) para acelerar a inferÃªncia.

---

## ğŸ“Œ Requisitos

Antes de rodar o projeto, certifique-se de ter instalado:

- Python 3.9+  
- [PyTorch](https://pytorch.org/) com suporte a CUDA (opcional, mas recomendado)  
- Pacotes necessÃ¡rios:
  ```bash
  pip install --upgrade torch transformers accelerate
````

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```
tinyllama/
â”‚â”€â”€ main.py      # CÃ³digo principal do chatbot
â”‚â”€â”€ README.md    # DocumentaÃ§Ã£o
```

---

## â–¶ï¸ Como Executar

Clone o repositÃ³rio:

```bash
git clone https://github.com/vitor-souza-ime/tinyllama.git
cd tinyllama
```

Execute o chatbot:

```bash
python main.py
```

---

## ğŸ’» Uso

Quando rodar o programa, vocÃª verÃ¡ algo assim:

```
=== Chat com TinyLlama-1.1B-Chat ===
Digite 'sair' para encerrar.
```

Depois basta digitar suas perguntas:

```
VocÃª: O que Ã© machine learning?
TinyLlama: Machine learning Ã© uma Ã¡rea da inteligÃªncia artificial que ensina computadores a aprenderem a partir de dados...
```

Para encerrar o chat:

```
VocÃª: sair
Encerrando o chat. AtÃ© mais!
```

---

## âš¡ Recursos TÃ©cnicos

* **Modelo:** TinyLlama-1.1B-Chat-v1.0
* **GeraÃ§Ã£o de texto:** `transformers.pipeline`
* **HistÃ³rico de mensagens:** suporte a mÃºltiplas interaÃ§Ãµes no estilo chat
* **AceleraÃ§Ã£o:** utiliza GPU automaticamente se disponÃ­vel (`device_map="auto"`)
* **EficiÃªncia:** roda em `torch_dtype=torch.bfloat16` para reduzir uso de memÃ³ria

---

## ğŸ“Š Verificar InstalaÃ§Ã£o do PyTorch

Para confirmar se sua instalaÃ§Ã£o do PyTorch reconhece a GPU, rode:

```python
import torch
print("VersÃ£o do PyTorch:", torch.__version__)
print("CUDA disponÃ­vel:", torch.cuda.is_available())
print("VersÃ£o do CUDA:", torch.version.cuda)
```

---

## ğŸ“œ LicenÃ§a

Este projeto Ã© apenas para fins de estudo e demonstraÃ§Ã£o. O modelo TinyLlama Ã© disponibilizado pela comunidade de pesquisa, consulte a [licenÃ§a oficial](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) para detalhes.

